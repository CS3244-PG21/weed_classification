{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-01 02:08:54.162451: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Label</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20160928-140314-0.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>Chinee apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20160928-140337-0.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>Chinee apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20160928-140731-0.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>Chinee apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20160928-140747-0.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>Chinee apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20160928-141107-0.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>Chinee apple</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Filename  Label       Species\n",
       "0  20160928-140314-0.jpg      0  Chinee apple\n",
       "1  20160928-140337-0.jpg      0  Chinee apple\n",
       "2  20160928-140731-0.jpg      0  Chinee apple\n",
       "3  20160928-140747-0.jpg      0  Chinee apple\n",
       "4  20160928-141107-0.jpg      0  Chinee apple"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# File paths\n",
    "image_dir = '../images'\n",
    "labels_df = pd.read_csv('../labels.csv')\n",
    "\n",
    "# Extract file names and labels\n",
    "image_filenames = labels_df['Filename'].values\n",
    "y = labels_df['Label'].values\n",
    "\n",
    "# Construct full image paths\n",
    "image_paths = [os.path.join(image_dir, fname) for fname in image_filenames]\n",
    "\n",
    "# Ensure images and labels are aligned\n",
    "if len(image_paths) != len(y):\n",
    "    raise ValueError(\"Number of images and labels do not match.\")\n",
    "\n",
    "labels_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset distribution:\n",
      " Label  Count        Species\n",
      "     8   7285       Negative\n",
      "     0    900   Chinee apple\n",
      "     6    859      Siam weed\n",
      "     1    851        Lantana\n",
      "     4    849 Prickly acacia\n",
      "     2    825    Parkinsonia\n",
      "     3    818     Parthenium\n",
      "     7    813     Snake weed\n",
      "     5    807    Rubber vine\n",
      "\n",
      "Testing dataset distribution:\n",
      " Label  Count        Species\n",
      "     8   1821       Negative\n",
      "     0    225   Chinee apple\n",
      "     6    215      Siam weed\n",
      "     1    213        Lantana\n",
      "     4    213 Prickly acacia\n",
      "     2    206    Parkinsonia\n",
      "     3    204     Parthenium\n",
      "     7    203     Snake weed\n",
      "     5    202    Rubber vine\n"
     ]
    }
   ],
   "source": [
    "# Split into training and testing datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(image_paths, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Create label-to-species mapping for displaying label counts\n",
    "label_to_species = dict(zip(labels_df['Label'], labels_df['Species']))\n",
    "\n",
    "# Label distribution\n",
    "def print_label_distribution(y_train, y_test, label_to_species):\n",
    "    # Create label counts for train and test datasets\n",
    "    train_label_counts = pd.Series(y_train).value_counts().reset_index()\n",
    "    test_label_counts = pd.Series(y_test).value_counts().reset_index()\n",
    "\n",
    "    # Rename columns\n",
    "    train_label_counts.columns = ['Label', 'Count']\n",
    "    test_label_counts.columns = ['Label', 'Count']\n",
    "\n",
    "    # Map species to the label counts\n",
    "    train_label_counts['Species'] = train_label_counts['Label'].map(label_to_species)\n",
    "    test_label_counts['Species'] = test_label_counts['Label'].map(label_to_species)\n",
    "\n",
    "    # Display the distributions\n",
    "    print(\"Training dataset distribution:\")\n",
    "    print(train_label_counts.to_string(index=False))\n",
    "\n",
    "    print(\"\\nTesting dataset distribution:\")\n",
    "    print(test_label_counts.to_string(index=False))\n",
    "\n",
    "print_label_distribution(y_train, y_test, label_to_species)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with imbalance data\n",
    "\n",
    "To mitigate class imbalance, I will randomly select Negative instances (Label is 8) to balance with other classes. \n",
    "Undersampling will only be performed on the training set to prevent the model from overfitting to the Negative instances. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform undersampling\n",
    "def undersample_classes(X_train, y_train, target_size=800):\n",
    "    # Create DataFrame with image paths and corresponding labels\n",
    "    train_df = pd.DataFrame({'Filename': X_train, 'Label': y_train})\n",
    "    \n",
    "    # Initialize empty list to hold undersampled data\n",
    "    undersampled_df = []\n",
    "\n",
    "    # Iterate through each class (label)\n",
    "    for label in np.unique(y_train):\n",
    "        # Get the subset of data for this class\n",
    "        class_subset = train_df[train_df['Label'] == label]\n",
    "        \n",
    "        # Sample 'target_size' number of images from each class\n",
    "        class_sample = class_subset.sample(n=target_size, random_state=42)\n",
    "        \n",
    "        # Append the sampled data to the list\n",
    "        undersampled_df.append(class_sample)\n",
    "    \n",
    "    # Combine the undersampled data into one DataFrame\n",
    "    undersampled_df = pd.concat(undersampled_df, ignore_index=True)\n",
    "    \n",
    "    # Return the undersampled image paths and labels\n",
    "    X_train_balanced = undersampled_df['Filename'].values\n",
    "    y_train_balanced = undersampled_df['Label'].values\n",
    "    \n",
    "    return X_train_balanced, y_train_balanced\n",
    "\n",
    "# Perform the undersampling\n",
    "X_train_balanced, y_train_balanced = undersample_classes(X_train, y_train, target_size=800)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split balanced training dataset into training and validation set\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_balanced, y_train_balanced, test_size=0.125, stratify=y_train_balanced, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset distribution:\n",
      "   Label  Count\n",
      "0      6    700\n",
      "1      8    700\n",
      "2      4    700\n",
      "3      5    700\n",
      "4      2    700\n",
      "5      1    700\n",
      "6      7    700\n",
      "7      0    700\n",
      "8      3    700\n",
      "\n",
      "Validation dataset distribution:\n",
      "   Label  Count\n",
      "0      0    100\n",
      "1      5    100\n",
      "2      8    100\n",
      "3      1    100\n",
      "4      3    100\n",
      "5      7    100\n",
      "6      6    100\n",
      "7      4    100\n",
      "8      2    100\n"
     ]
    }
   ],
   "source": [
    "# Check the distribution\n",
    "\n",
    "train_label_counts = pd.Series(y_train).value_counts().reset_index()\n",
    "val_label_counts = pd.Series(y_val).value_counts().reset_index()\n",
    "\n",
    "train_label_counts.columns = ['Label', 'Count']\n",
    "val_label_counts.columns = ['Label', 'Count']\n",
    "\n",
    "print(\"Training dataset distribution:\")\n",
    "print(train_label_counts)\n",
    "\n",
    "print(\"\\nValidation dataset distribution:\")\n",
    "print(val_label_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Pre-processing (resizing, normalization, edge detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2  # For edge detection\n",
    "\n",
    "# Function to load and decode images\n",
    "def load_image(image_path):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)  # Decode as RGB image\n",
    "    return image\n",
    "\n",
    "# Preprocess image: resize and normalize\n",
    "def preprocess_image(image, target_size=(224, 224)):\n",
    "    image = tf.image.resize(image, target_size)  # Resize image to the target size\n",
    "    image = image / 255.0  # Normalize to [0, 1]\n",
    "    return image\n",
    "\n",
    "# Edge detection using TensorFlow's sobel_edges\n",
    "def edge_detection_tf(image):\n",
    "    gray = tf.image.rgb_to_grayscale(image)  # Convert RGB to grayscale\n",
    "    \n",
    "    # Add a batch dimension for the edge detection function\n",
    "    gray = tf.expand_dims(gray, axis=0)  # Add batch dimension (shape: [1, H, W, 1])\n",
    "    \n",
    "    sobel_edges = tf.image.sobel_edges(gray)  # Returns gradients in x and y\n",
    "    \n",
    "    # Remove batch dimension after sobel operation (result shape: [H, W, 2])\n",
    "    sobel_edges = tf.squeeze(sobel_edges, axis=0)\n",
    "    \n",
    "    # Compute edge magnitude (magnitude of gradients)\n",
    "    edge_magnitude = tf.sqrt(tf.reduce_sum(tf.square(sobel_edges), axis=-1))  # Compute edge magnitude\n",
    "    \n",
    "    # Resize edge magnitude to match the image size\n",
    "    edge_magnitude = tf.image.resize(edge_magnitude, [224, 224])  # Resize if needed\n",
    "    return edge_magnitude\n",
    "\n",
    "\n",
    "# Function to combine original image and edge detection result\n",
    "def combine_image_and_edges(image):\n",
    "    edges = edge_detection_tf(image)  # Perform edge detection using TensorFlow\n",
    "    image_with_edges = tf.concat([image, edges], axis=-1)  # Combine RGB image with edge features\n",
    "    return image_with_edges\n",
    "\n",
    "# Create the dataset for training and testing\n",
    "def create_dataset(image_paths, labels, batch_size=32, augment=False):\n",
    "    X_processed = []\n",
    "    y_processed = []\n",
    "\n",
    "    for image_path, label in zip(image_paths, labels):\n",
    "        # Load and preprocess the image\n",
    "        image = load_image(image_path)\n",
    "        image = preprocess_image(image)\n",
    "        \n",
    "        # Combine the RGB image with edges\n",
    "        image_with_edges = combine_image_and_edges(image)\n",
    "        \n",
    "        # Append processed image and label\n",
    "        X_processed.append(image_with_edges)\n",
    "        y_processed.append(label)\n",
    "\n",
    "    # Convert lists to NumPy arrays for further use\n",
    "    X_processed = np.array(X_processed)\n",
    "    y_processed = np.array(y_processed)\n",
    "\n",
    "    return X_processed, y_processed\n",
    "\n",
    "X_train_processed, y_train_processed = create_dataset(X_train, y_train)\n",
    "X_val_processed, y_val_processed = create_dataset(X_val, y_val)\n",
    "X_test_processed, y_test_processed = create_dataset(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train_processed: (6300, 224, 224, 4)\n",
      "Shape of y_train_processed: (6300,)\n",
      "Shape of X_val_processed: (900, 224, 224, 4)\n",
      "Shape of y_val_processed: (900,)\n",
      "Shape of X_test_processed: (3502, 224, 224, 4)\n",
      "Shape of y_test_processed: (3502,)\n"
     ]
    }
   ],
   "source": [
    "# Check the shape of the input data for train, validation, and test sets\n",
    "print(\"Shape of X_train_processed:\", X_train_processed.shape)\n",
    "print(\"Shape of y_train_processed:\", y_train_processed.shape)\n",
    "\n",
    "print(\"Shape of X_val_processed:\", X_val_processed.shape)\n",
    "print(\"Shape of y_val_processed:\", y_val_processed.shape)\n",
    "\n",
    "print(\"Shape of X_test_processed:\", X_test_processed.shape)\n",
    "print(\"Shape of y_test_processed:\", y_test_processed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Perform one-hot encoding for the labels\n",
    "y_train_processed = to_categorical(y_train_processed, num_classes=9)\n",
    "y_val_processed = to_categorical(y_val_processed, num_classes=9)\n",
    "y_test_processed = to_categorical(y_test_processed, num_classes=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Input\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "inputs = Input(shape=(224, 224, 4)) \n",
    "\n",
    "x = layers.Conv2D(64, (3, 3), padding=\"same\", strides=2)(inputs)\n",
    "x = layers.Conv2D(64, (3, 3), padding=\"same\", strides=2)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "layer1 = layers.ReLU()(x)\n",
    "\n",
    "x = layers.Conv2D(64, (3, 3), padding=\"same\")(layer1)\n",
    "x = layers.Conv2D(64, (3, 3), padding=\"same\")(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "layer2 = layers.ReLU()(x)\n",
    "\n",
    "x = layers.Conv2D(128, (3, 3), padding=\"same\")(layer2)\n",
    "x = layers.Conv2D(128, (3, 3), padding=\"same\")(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "layer3 = layers.ReLU()(x)\n",
    "\n",
    "x = layers.Conv2D(128, (3, 3), padding=\"same\")(layer3)\n",
    "x = layers.Conv2D(128, (3, 3), padding=\"same\")(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "layer4 = layers.ReLU()(x)\n",
    "\n",
    "x = layers.Conv2D(256, (3, 3), padding=\"same\", strides=2)(layer4)\n",
    "x = layers.Conv2D(256, (3, 3), padding=\"same\", strides=2)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "layer5 = layers.ReLU()(x)\n",
    "\n",
    "x = layers.GlobalMaxPooling2D()(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(9, activation=\"softmax\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "197/197 [==============================] - 738s 4s/step - loss: 2.5979 - accuracy: 0.2319 - precision: 0.2587 - recall: 0.1178 - val_loss: 4.6115 - val_accuracy: 0.1211 - val_precision: 0.1278 - val_recall: 0.1200\n",
      "Epoch 2/20\n",
      "197/197 [==============================] - 685s 3s/step - loss: 1.8098 - accuracy: 0.3300 - precision: 0.4214 - recall: 0.1208 - val_loss: 2.6872 - val_accuracy: 0.2422 - val_precision: 0.3079 - val_recall: 0.1656\n",
      "Epoch 3/20\n",
      "197/197 [==============================] - 671s 3s/step - loss: 1.6615 - accuracy: 0.3732 - precision: 0.5052 - recall: 0.1532 - val_loss: 1.7049 - val_accuracy: 0.3711 - val_precision: 0.4748 - val_recall: 0.1467\n",
      "Epoch 4/20\n",
      "197/197 [==============================] - 682s 3s/step - loss: 1.5899 - accuracy: 0.4068 - precision: 0.5437 - recall: 0.1897 - val_loss: 1.8303 - val_accuracy: 0.3711 - val_precision: 0.4619 - val_recall: 0.2356\n",
      "Epoch 5/20\n",
      "197/197 [==============================] - 645s 3s/step - loss: 1.5404 - accuracy: 0.4243 - precision: 0.5645 - recall: 0.1986 - val_loss: 1.6364 - val_accuracy: 0.4011 - val_precision: 0.5466 - val_recall: 0.2344\n",
      "Epoch 6/20\n",
      "197/197 [==============================] - 673s 3s/step - loss: 1.4898 - accuracy: 0.4522 - precision: 0.5970 - recall: 0.2310 - val_loss: 2.1655 - val_accuracy: 0.3356 - val_precision: 0.3647 - val_recall: 0.2411\n",
      "Epoch 7/20\n",
      "197/197 [==============================] - 893s 5s/step - loss: 1.4308 - accuracy: 0.4741 - precision: 0.6029 - recall: 0.2506 - val_loss: 2.4602 - val_accuracy: 0.3111 - val_precision: 0.4340 - val_recall: 0.1644\n",
      "Epoch 8/20\n",
      "197/197 [==============================] - 638s 3s/step - loss: 1.3684 - accuracy: 0.5025 - precision: 0.6434 - recall: 0.2981 - val_loss: 1.4459 - val_accuracy: 0.5000 - val_precision: 0.6362 - val_recall: 0.3400\n",
      "Epoch 9/20\n",
      "197/197 [==============================] - 626s 3s/step - loss: 1.3360 - accuracy: 0.5130 - precision: 0.6404 - recall: 0.3189 - val_loss: 2.1687 - val_accuracy: 0.3044 - val_precision: 0.3481 - val_recall: 0.2089\n",
      "Epoch 10/20\n",
      "197/197 [==============================] - 616s 3s/step - loss: 1.2954 - accuracy: 0.5303 - precision: 0.6561 - recall: 0.3433 - val_loss: 1.6290 - val_accuracy: 0.4156 - val_precision: 0.5298 - val_recall: 0.2667\n",
      "Epoch 11/20\n",
      "197/197 [==============================] - 628s 3s/step - loss: 1.2655 - accuracy: 0.5333 - precision: 0.6746 - recall: 0.3578 - val_loss: 1.6372 - val_accuracy: 0.4622 - val_precision: 0.5265 - val_recall: 0.3422\n",
      "Epoch 12/20\n",
      "197/197 [==============================] - 624s 3s/step - loss: 1.2254 - accuracy: 0.5605 - precision: 0.6955 - recall: 0.3865 - val_loss: 1.9372 - val_accuracy: 0.4022 - val_precision: 0.5705 - val_recall: 0.1933\n",
      "Epoch 13/20\n",
      "197/197 [==============================] - 630s 3s/step - loss: 1.1874 - accuracy: 0.5749 - precision: 0.7103 - recall: 0.4200 - val_loss: 1.2782 - val_accuracy: 0.5644 - val_precision: 0.6395 - val_recall: 0.4100\n",
      "Epoch 14/20\n",
      "197/197 [==============================] - 631s 3s/step - loss: 1.1749 - accuracy: 0.5776 - precision: 0.7043 - recall: 0.4121 - val_loss: 1.3496 - val_accuracy: 0.5344 - val_precision: 0.6268 - val_recall: 0.3956\n",
      "Epoch 15/20\n",
      "197/197 [==============================] - 636s 3s/step - loss: 1.1302 - accuracy: 0.5924 - precision: 0.7173 - recall: 0.4433 - val_loss: 1.5581 - val_accuracy: 0.4478 - val_precision: 0.6359 - val_recall: 0.2833\n",
      "Epoch 16/20\n",
      "197/197 [==============================] - 653s 3s/step - loss: 1.0938 - accuracy: 0.6052 - precision: 0.7321 - recall: 0.4637 - val_loss: 1.4341 - val_accuracy: 0.5589 - val_precision: 0.6026 - val_recall: 0.4633\n",
      "Epoch 17/20\n",
      "197/197 [==============================] - 24642s 126s/step - loss: 1.0498 - accuracy: 0.6192 - precision: 0.7401 - recall: 0.4895 - val_loss: 3.1679 - val_accuracy: 0.2600 - val_precision: 0.2845 - val_recall: 0.2200\n",
      "Epoch 18/20\n",
      "197/197 [==============================] - 649s 3s/step - loss: 1.0525 - accuracy: 0.6219 - precision: 0.7330 - recall: 0.4859 - val_loss: 1.2306 - val_accuracy: 0.5678 - val_precision: 0.6558 - val_recall: 0.5144\n",
      "Epoch 19/20\n",
      "197/197 [==============================] - 611s 3s/step - loss: 1.0122 - accuracy: 0.6378 - precision: 0.7526 - recall: 0.5065 - val_loss: 1.0664 - val_accuracy: 0.6167 - val_precision: 0.7210 - val_recall: 0.4767\n",
      "Epoch 20/20\n",
      "197/197 [==============================] - 640s 3s/step - loss: 0.9935 - accuracy: 0.6398 - precision: 0.7514 - recall: 0.5149 - val_loss: 1.1733 - val_accuracy: 0.5922 - val_precision: 0.7003 - val_recall: 0.5089\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Model(inputs, outputs, name=\"cnn_model\")\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss=\"categorical_crossentropy\", metrics=[\"accuracy\", \"Precision\", \"Recall\"])\n",
    "\n",
    "history = model.fit(X_train_processed, \n",
    "                    y_train_processed, \n",
    "                    epochs=20, \n",
    "                    batch_size=32, \n",
    "                    validation_data=(X_val_processed, y_val_processed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the time constraints, we were only able to train until 20 epochs. However, given that the model's performance on both the training dataset and validation dataset were gradually increasing, there is a possibility of more improvements in the model when the number of epochs is increased. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 136s 1s/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_processed)\n",
    "\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_test_processed = np.argmax(y_test_processed, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro-averaged Precision: 0.62\n",
      "Micro-averaged Recall: 0.62\n",
      "Micro-averaged F1 score: 0.62\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      " Chinese Apple       0.75      0.04      0.08       225\n",
      "       Lantana       0.37      0.77      0.50       213\n",
      "   Parkinsonia       0.56      0.67      0.61       206\n",
      "    Parthenium       0.41      0.75      0.53       204\n",
      "Prickly acacia       0.63      0.75      0.69       213\n",
      "   Rubber vine       0.45      0.83      0.59       202\n",
      "     Siam weed       0.50      0.77      0.60       215\n",
      "    Snake Weed       0.41      0.52      0.46       203\n",
      "     Negatives       0.90      0.60      0.72      1821\n",
      "\n",
      "      accuracy                           0.62      3502\n",
      "     macro avg       0.55      0.63      0.53      3502\n",
      "  weighted avg       0.72      0.62      0.62      3502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Evaluate using micro-averaged precision, recall, and F1 scoare \n",
    "precision_micro = precision_score(y_test_processed, y_pred_classes, average='micro')\n",
    "recall_micro = recall_score(y_test_processed, y_pred_classes, average='micro')\n",
    "f1_micro = f1_score(y_test_processed, y_pred_classes, average='micro')\n",
    "\n",
    "\n",
    "# Output the evaluation metrics\n",
    "print(f\"Micro-averaged Precision: {precision_micro:.2f}\")\n",
    "print(f\"Micro-averaged Recall: {recall_micro:.2f}\")\n",
    "print(f\"Micro-averaged F1 score: {f1_micro:.2f}\")\n",
    "\n",
    "# Define the label mapping\n",
    "target_names = ['Chinese Apple', 'Lantana', 'Parkinsonia', 'Parthenium', \n",
    "                'Prickly acacia', 'Rubber vine', 'Siam weed', 'Snake Weed', 'Negatives']\n",
    "\n",
    "# Classification Report\n",
    "print(\"Classification Report for cnn:\")\n",
    "print(classification_report(y_test_processed, y_pred_classes, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the testing dataset is imbalanced, we must use micro-averaged evalution metrics to interpret model's performance. The micro-averaged F1 score of the model on the testing dataset is **0.62**. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
