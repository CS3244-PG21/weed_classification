{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GradCAM Evaluation\n",
    "\n",
    "### GradCAM Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388ms/step\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Dense' object has no attribute 'output_shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 97\u001b[0m\n\u001b[1;32m     94\u001b[0m predicted_class \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(predictions[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m# Initialize GradCAM\u001b[39;00m\n\u001b[0;32m---> 97\u001b[0m cam \u001b[38;5;241m=\u001b[39m \u001b[43mGradCAM\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredicted_class\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m heatmap \u001b[38;5;241m=\u001b[39m cam\u001b[38;5;241m.\u001b[39mcompute_heatmap(preprocessed_test)\n\u001b[1;32m    100\u001b[0m \u001b[38;5;66;03m# Overlay heatmap on the original image\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[19], line 15\u001b[0m, in \u001b[0;36mGradCAM.__init__\u001b[0;34m(self, model, classIdx, layerName)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Automatically find the last convolutional layer if none is provided\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayerName \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 15\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayerName \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_target_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[19], line 20\u001b[0m, in \u001b[0;36mGradCAM.find_target_layer\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind_target_layer\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m# Find the last convolutional layer\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mlayers):\n\u001b[0;32m---> 20\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_shape\u001b[49m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m4\u001b[39m:  \u001b[38;5;66;03m# Check for 4D outputs\u001b[39;00m\n\u001b[1;32m     21\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m layer\u001b[38;5;241m.\u001b[39mname\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not find a 4D layer. Cannot apply GradCAM.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Dense' object has no attribute 'output_shape'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "class GradCAM:\n",
    "    def __init__(self, model, classIdx, layerName=None):\n",
    "        self.model = model\n",
    "        self.classIdx = classIdx\n",
    "        self.layerName = layerName\n",
    "\n",
    "        # Automatically find the last convolutional layer if none is provided\n",
    "        if self.layerName is None:\n",
    "            self.layerName = self.find_target_layer()\n",
    "    \n",
    "    def find_target_layer(self):\n",
    "        # Find the last convolutional layer\n",
    "        for layer in reversed(self.model.layers):\n",
    "            if len(layer.output_shape) == 4:  # Check for 4D outputs\n",
    "                return layer.name\n",
    "        raise ValueError(\"Could not find a 4D layer. Cannot apply GradCAM.\")\n",
    "\n",
    "    def compute_heatmap(self, image, eps=1e-8):\n",
    "        # Build a model that maps the inputs to the activations of the last conv layer and the outputs\n",
    "        gradModel = Model(\n",
    "            inputs=[self.model.inputs],\n",
    "            outputs=[self.model.get_layer(self.layerName).output, self.model.output]\n",
    "        )\n",
    "\n",
    "        # Record operations for gradient computation\n",
    "        with tf.GradientTape() as tape:\n",
    "            inputs = tf.cast(image, tf.float32)\n",
    "            (convOutputs, predictions) = gradModel(inputs)\n",
    "            loss = predictions[:, self.classIdx]\n",
    "\n",
    "        # Compute the gradients\n",
    "        grads = tape.gradient(loss, convOutputs)\n",
    "\n",
    "        # Compute guided gradients\n",
    "        castConvOutputs = tf.cast(convOutputs > 0, \"float32\")\n",
    "        castGrads = tf.cast(grads > 0, \"float32\")\n",
    "        guidedGrads = castConvOutputs * castGrads * grads\n",
    "\n",
    "        # Average the gradients\n",
    "        weights = tf.reduce_mean(guidedGrads, axis=(0, 1, 2))\n",
    "        \n",
    "        # Compute the weighted sum of feature maps\n",
    "        convOutputs = convOutputs[0]\n",
    "        cam = tf.reduce_sum(tf.multiply(weights, convOutputs), axis=-1)\n",
    "\n",
    "        # Resize heatmap to match input image dimensions\n",
    "        (w, h) = (image.shape[2], image.shape[1])\n",
    "        heatmap = cv2.resize(cam.numpy(), (w, h))\n",
    "\n",
    "        # Normalize the heatmap\n",
    "        numer = heatmap - np.min(heatmap)\n",
    "        denom = (heatmap.max() - heatmap.min()) + eps\n",
    "        heatmap = numer / denom\n",
    "        heatmap = (heatmap * 255).astype(\"uint8\")\n",
    "        return heatmap\n",
    "\n",
    "    def overlay_heatmap(self, heatmap, image, alpha=0.5, colormap=cv2.COLORMAP_JET):\n",
    "        # Apply colormap to heatmap\n",
    "        heatmap = cv2.applyColorMap(heatmap, colormap)\n",
    "\n",
    "        # Overlay heatmap on the image\n",
    "        output = cv2.addWeighted(image, alpha, heatmap, 1 - alpha, 0)\n",
    "        return (heatmap, output)\n",
    "\n",
    "def preprocess(img):\n",
    "    # Resize to match the model's input dimensions\n",
    "    img = cv2.resize(img, (224, 224))\n",
    "    # Convert the image to RGB if needed (ensure 3 channels)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    # Normalize pixel values to [0, 1] or preprocess as per the model's requirements\n",
    "    return img / 255.0  # Normalize to [0, 1]\n",
    "\n",
    "# Example GradCAM Execution\n",
    "test = cv2.imread(\"../images/20160928-140314-0.jpg\")\n",
    "test = cv2.resize(test, (224, 224))  # Ensure image is resized to model input dimensions\n",
    "test = cv2.cvtColor(test, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Preprocess the test image\n",
    "preprocessed_test = preprocess(test)\n",
    "preprocessed_test = np.expand_dims(preprocessed_test, axis=0)\n",
    "\n",
    "# Load your trained model (replace with your model)\n",
    "model = tf.keras.applications.MobileNetV2(weights=\"imagenet\")\n",
    "model = Model(inputs=model.input, outputs=model.output)  # Ensure it's compatible with GradCAM\n",
    "\n",
    "# Predict the class of the test image\n",
    "predictions = model.predict(preprocessed_test)\n",
    "predicted_class = np.argmax(predictions[0])\n",
    "\n",
    "# Initialize GradCAM\n",
    "cam = GradCAM(model, predicted_class)\n",
    "heatmap = cam.compute_heatmap(preprocessed_test)\n",
    "\n",
    "# Overlay heatmap on the original image\n",
    "(heatmap, output) = cam.overlay_heatmap(heatmap, test, alpha=0.6)\n",
    "\n",
    "# Display the results\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(test / 255.0)\n",
    "plt.title(\"Original Image\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(cv2.cvtColor(output, cv2.COLOR_BGR2RGB))\n",
    "plt.title(\"GradCAM Overlay\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
