{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GradCAM Evaluation : CNN\n",
    "\n",
    "### GradCAM Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Label</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20160928-140314-0.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>Chinee apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20160928-140337-0.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>Chinee apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20160928-140731-0.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>Chinee apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20160928-140747-0.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>Chinee apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20160928-141107-0.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>Chinee apple</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Filename  Label       Species\n",
       "0  20160928-140314-0.jpg      0  Chinee apple\n",
       "1  20160928-140337-0.jpg      0  Chinee apple\n",
       "2  20160928-140731-0.jpg      0  Chinee apple\n",
       "3  20160928-140747-0.jpg      0  Chinee apple\n",
       "4  20160928-141107-0.jpg      0  Chinee apple"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# File paths\n",
    "image_dir = '../images'\n",
    "labels_df = pd.read_csv('../labels.csv')\n",
    "\n",
    "# Extract file names and labels\n",
    "image_filenames = labels_df['Filename'].values\n",
    "y = labels_df['Label'].values\n",
    "\n",
    "# Construct full image paths\n",
    "image_paths = [os.path.join(image_dir, fname) for fname in image_filenames]\n",
    "\n",
    "# Ensure images and labels are aligned\n",
    "if len(image_paths) != len(y):\n",
    "    raise ValueError(\"Number of images and labels do not match.\")\n",
    "\n",
    "labels_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset distribution:\n",
      " Label  Count        Species\n",
      "     8   7285       Negative\n",
      "     0    900   Chinee apple\n",
      "     6    859      Siam weed\n",
      "     1    851        Lantana\n",
      "     4    849 Prickly acacia\n",
      "     2    825    Parkinsonia\n",
      "     3    818     Parthenium\n",
      "     7    813     Snake weed\n",
      "     5    807    Rubber vine\n",
      "\n",
      "Testing dataset distribution:\n",
      " Label  Count        Species\n",
      "     8   1821       Negative\n",
      "     0    225   Chinee apple\n",
      "     6    215      Siam weed\n",
      "     1    213        Lantana\n",
      "     4    213 Prickly acacia\n",
      "     2    206    Parkinsonia\n",
      "     3    204     Parthenium\n",
      "     7    203     Snake weed\n",
      "     5    202    Rubber vine\n"
     ]
    }
   ],
   "source": [
    "# Split into training and testing datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(image_paths, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Create label-to-species mapping for displaying label counts\n",
    "label_to_species = dict(zip(labels_df['Label'], labels_df['Species']))\n",
    "\n",
    "# Label distribution\n",
    "def print_label_distribution(y_train, y_test, label_to_species):\n",
    "    # Create label counts for train and test datasets\n",
    "    train_label_counts = pd.Series(y_train).value_counts().reset_index()\n",
    "    test_label_counts = pd.Series(y_test).value_counts().reset_index()\n",
    "\n",
    "    # Rename columns\n",
    "    train_label_counts.columns = ['Label', 'Count']\n",
    "    test_label_counts.columns = ['Label', 'Count']\n",
    "\n",
    "    # Map species to the label counts\n",
    "    train_label_counts['Species'] = train_label_counts['Label'].map(label_to_species)\n",
    "    test_label_counts['Species'] = test_label_counts['Label'].map(label_to_species)\n",
    "\n",
    "    # Display the distributions\n",
    "    print(\"Training dataset distribution:\")\n",
    "    print(train_label_counts.to_string(index=False))\n",
    "\n",
    "    print(\"\\nTesting dataset distribution:\")\n",
    "    print(test_label_counts.to_string(index=False))\n",
    "\n",
    "print_label_distribution(y_train, y_test, label_to_species)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with imbalance data\n",
    "\n",
    "To mitigate class imbalance, I will randomly select Negative instances (Label is 8) to balance with other classes. \n",
    "Undersampling will only be performed on the training set to prevent the model from overfitting to the Negative instances. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform undersampling\n",
    "def undersample_classes(X_train, y_train, target_size=800):\n",
    "    # Create DataFrame with image paths and corresponding labels\n",
    "    train_df = pd.DataFrame({'Filename': X_train, 'Label': y_train})\n",
    "    \n",
    "    # Initialize empty list to hold undersampled data\n",
    "    undersampled_df = []\n",
    "\n",
    "    # Iterate through each class (label)\n",
    "    for label in np.unique(y_train):\n",
    "        # Get the subset of data for this class\n",
    "        class_subset = train_df[train_df['Label'] == label]\n",
    "        \n",
    "        # Sample 'target_size' number of images from each class\n",
    "        class_sample = class_subset.sample(n=target_size, random_state=42)\n",
    "        \n",
    "        # Append the sampled data to the list\n",
    "        undersampled_df.append(class_sample)\n",
    "    \n",
    "    # Combine the undersampled data into one DataFrame\n",
    "    undersampled_df = pd.concat(undersampled_df, ignore_index=True)\n",
    "    \n",
    "    # Return the undersampled image paths and labels\n",
    "    X_train_balanced = undersampled_df['Filename'].values\n",
    "    y_train_balanced = undersampled_df['Label'].values\n",
    "    \n",
    "    return X_train_balanced, y_train_balanced\n",
    "\n",
    "# Perform the undersampling\n",
    "X_train_balanced, y_train_balanced = undersample_classes(X_train, y_train, target_size=800)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split balanced training dataset into training and validation set\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_balanced, y_train_balanced, test_size=0.125, stratify=y_train_balanced, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Pre-processing (resizing, normalization, edge detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2  # For edge detection\n",
    "\n",
    "# Function to load and decode images\n",
    "def load_image(image_path):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)  # Decode as RGB image\n",
    "    return image\n",
    "\n",
    "# Preprocess image: resize and normalize\n",
    "def preprocess_image(image, target_size=(224, 224)):\n",
    "    image = tf.image.resize(image, target_size)  # Resize image to the target size\n",
    "    image = image / 255.0  # Normalize to [0, 1]\n",
    "    return image\n",
    "\n",
    "# Edge detection using TensorFlow's sobel_edges\n",
    "def edge_detection_tf(image):\n",
    "    gray = tf.image.rgb_to_grayscale(image)  # Convert RGB to grayscale\n",
    "    \n",
    "    # Add a batch dimension for the edge detection function\n",
    "    gray = tf.expand_dims(gray, axis=0)  # Add batch dimension (shape: [1, H, W, 1])\n",
    "    \n",
    "    sobel_edges = tf.image.sobel_edges(gray)  # Returns gradients in x and y\n",
    "    \n",
    "    # Remove batch dimension after sobel operation (result shape: [H, W, 2])\n",
    "    sobel_edges = tf.squeeze(sobel_edges, axis=0)\n",
    "    \n",
    "    # Compute edge magnitude (magnitude of gradients)\n",
    "    edge_magnitude = tf.sqrt(tf.reduce_sum(tf.square(sobel_edges), axis=-1))  # Compute edge magnitude\n",
    "    \n",
    "    # Resize edge magnitude to match the image size\n",
    "    edge_magnitude = tf.image.resize(edge_magnitude, [224, 224])  # Resize if needed\n",
    "    return edge_magnitude\n",
    "\n",
    "\n",
    "# Function to combine original image and edge detection result\n",
    "def combine_image_and_edges(image):\n",
    "    edges = edge_detection_tf(image)  # Perform edge detection using TensorFlow\n",
    "    image_with_edges = tf.concat([image, edges], axis=-1)  # Combine RGB image with edge features\n",
    "    return image_with_edges\n",
    "\n",
    "# Create the dataset for training and testing\n",
    "def create_dataset(image_paths, labels, batch_size=32, augment=False):\n",
    "    X_processed = []\n",
    "    y_processed = []\n",
    "\n",
    "    for image_path, label in zip(image_paths, labels):\n",
    "        # Load and preprocess the image\n",
    "        image = load_image(image_path)\n",
    "        image = preprocess_image(image)\n",
    "        \n",
    "        # Combine the RGB image with edges\n",
    "        image_with_edges = combine_image_and_edges(image)\n",
    "        \n",
    "        # Append processed image and label\n",
    "        X_processed.append(image_with_edges)\n",
    "        y_processed.append(label)\n",
    "\n",
    "    # Convert lists to NumPy arrays for further use\n",
    "    X_processed = np.array(X_processed)\n",
    "    y_processed = np.array(y_processed)\n",
    "\n",
    "    return X_processed, y_processed\n",
    "\n",
    "X_train_processed, y_train_processed = create_dataset(X_train, y_train)\n",
    "X_val_processed, y_val_processed = create_dataset(X_val, y_val)\n",
    "X_test_processed, y_test_processed = create_dataset(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Perform one-hot encoding for the labels\n",
    "y_train_processed = to_categorical(y_train_processed, num_classes=9)\n",
    "y_val_processed = to_categorical(y_val_processed, num_classes=9)\n",
    "y_test_processed = to_categorical(y_test_processed, num_classes=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Input\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "inputs = Input(shape=(224, 224, 4)) \n",
    "\n",
    "x = layers.Conv2D(64, (3, 3), padding=\"same\", strides=2)(inputs)\n",
    "x = layers.Conv2D(64, (3, 3), padding=\"same\", strides=2)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "layer1 = layers.ReLU()(x)\n",
    "\n",
    "x = layers.Conv2D(64, (3, 3), padding=\"same\")(layer1)\n",
    "x = layers.Conv2D(64, (3, 3), padding=\"same\")(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "layer2 = layers.ReLU()(x)\n",
    "\n",
    "x = layers.Conv2D(128, (3, 3), padding=\"same\")(layer2)\n",
    "x = layers.Conv2D(128, (3, 3), padding=\"same\")(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "layer3 = layers.ReLU()(x)\n",
    "\n",
    "x = layers.Conv2D(128, (3, 3), padding=\"same\")(layer3)\n",
    "x = layers.Conv2D(128, (3, 3), padding=\"same\")(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "layer4 = layers.ReLU()(x)\n",
    "\n",
    "x = layers.Conv2D(256, (3, 3), padding=\"same\", strides=2)(layer4)\n",
    "x = layers.Conv2D(256, (3, 3), padding=\"same\", strides=2)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "layer5 = layers.ReLU()(x)\n",
    "\n",
    "x = layers.GlobalMaxPooling2D()(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(9, activation=\"softmax\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m483s\u001b[0m 2s/step - Precision: 0.2030 - Recall: 0.1131 - accuracy: 0.1955 - loss: 3.1984 - val_Precision: 0.3519 - val_Recall: 0.0211 - val_accuracy: 0.1189 - val_loss: 3.1622\n",
      "Epoch 2/20\n",
      "\u001b[1m 70/197\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m5:06\u001b[0m 2s/step - Precision: 0.4206 - Recall: 0.1006 - accuracy: 0.3065 - loss: 1.8018"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Model(inputs, outputs, name=\"cnn_model\")\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss=\"categorical_crossentropy\", metrics=[\"accuracy\", \"Precision\", \"Recall\"])\n",
    "\n",
    "history = model.fit(X_train_processed, \n",
    "                    y_train_processed, \n",
    "                    epochs=20, \n",
    "                    batch_size=32, \n",
    "                    validation_data=(X_val_processed, y_val_processed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 136s 1s/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_cnn = model.predict(X_test_processed)\n",
    "\n",
    "y_pred_classes = np.argmax(y_pred_cnn, axis=1)\n",
    "y_test_processed = np.argmax(y_test_processed, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test_processed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 114\u001b[0m\n\u001b[1;32m    110\u001b[0m     gradcam_visualize(model, X_test, y_test, num_classes\u001b[38;5;241m=\u001b[39mnum_classes, samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m    112\u001b[0m \u001b[38;5;66;03m# Example Usage\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;66;03m# Assume `X_test_processed` and `y_test_processed` are preprocessed test data and labels\u001b[39;00m\n\u001b[0;32m--> 114\u001b[0m evaluate_model_with_gradcam(model, \u001b[43mX_test_processed\u001b[49m, y_test_processed)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_test_processed' is not defined"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# GradCAM class remains the same as provided earlier\n",
    "\n",
    "class GradCAM:\n",
    "    def __init__(self, model, classIdx, layerName=None):\n",
    "        self.model = model\n",
    "        self.classIdx = classIdx\n",
    "        self.layerName = layerName\n",
    "\n",
    "        if self.layerName is None:\n",
    "            self.layerName = self.find_target_layer()\n",
    "\n",
    "    def find_target_layer(self):\n",
    "        for layer in reversed(self.model.layers):\n",
    "            if isinstance(layer, tf.keras.layers.Conv2D):\n",
    "                return layer.name\n",
    "        raise ValueError(\"Could not find a Conv2D layer. Cannot apply GradCAM.\")\n",
    "\n",
    "    def compute_heatmap(self, image, eps=1e-8):\n",
    "        gradModel = tf.keras.models.Model(\n",
    "            inputs=[self.model.inputs],\n",
    "            outputs=[self.model.get_layer(self.layerName).output, self.model.output]\n",
    "        )\n",
    "        with tf.GradientTape() as tape:\n",
    "            inputs = tf.cast(image, tf.float32)\n",
    "            (convOutputs, predictions) = gradModel(inputs)\n",
    "            loss = predictions[:, self.classIdx]\n",
    "\n",
    "        grads = tape.gradient(loss, convOutputs)\n",
    "        castConvOutputs = tf.cast(convOutputs > 0, \"float32\")\n",
    "        castGrads = tf.cast(grads > 0, \"float32\")\n",
    "        guidedGrads = castConvOutputs * castGrads * grads\n",
    "\n",
    "        weights = tf.reduce_mean(guidedGrads, axis=(0, 1, 2))\n",
    "        convOutputs = convOutputs[0]\n",
    "        cam = tf.reduce_sum(tf.multiply(weights, convOutputs), axis=-1)\n",
    "\n",
    "        (w, h) = (image.shape[2], image.shape[1])\n",
    "        heatmap = cv2.resize(cam.numpy(), (w, h))\n",
    "\n",
    "        numer = heatmap - np.min(heatmap)\n",
    "        denom = (heatmap.max() - heatmap.min()) + eps\n",
    "        heatmap = numer / denom\n",
    "        heatmap = (heatmap * 255).astype(\"uint8\")\n",
    "        return heatmap\n",
    "\n",
    "    def overlay_heatmap(self, heatmap, image, alpha=0.5, colormap=cv2.COLORMAP_JET):\n",
    "        heatmap = cv2.applyColorMap(heatmap, colormap)\n",
    "        if image.shape[-1] == 4:\n",
    "            image = image[:, :, :3]\n",
    "        output = cv2.addWeighted(image, alpha, heatmap, 1 - alpha, 0)\n",
    "        return (heatmap, output)\n",
    "\n",
    "# Function for GradCAM visualization\n",
    "def gradcam_visualize(model, X_test, y_test, num_classes=9, samples=5):\n",
    "    for i in range(samples):\n",
    "        test_image = X_test[i]\n",
    "        true_label = np.argmax(y_test[i])\n",
    "        pred_probs = model.predict(np.expand_dims(test_image, axis=0))\n",
    "        pred_label = np.argmax(pred_probs)\n",
    "\n",
    "        cam = GradCAM(model, pred_label)\n",
    "        heatmap = cam.compute_heatmap(np.expand_dims(test_image, axis=0))\n",
    "        (heatmap, overlay) = cam.overlay_heatmap(heatmap, test_image, alpha=0.6)\n",
    "\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(test_image[:, :, :3])\n",
    "        plt.title(f\"True: {true_label}, Predicted: {pred_label}\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(cv2.cvtColor(overlay, cv2.COLOR_BGR2RGB))\n",
    "        plt.title(\"GradCAM Overlay\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n",
    "\n",
    "# Evaluate CNN model\n",
    "def evaluate_model_with_gradcam(model, X_test, y_test, num_classes=9):\n",
    "    # Predict labels\n",
    "    y_pred_probs = model.predict(X_test)\n",
    "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "    y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "    # Classification report\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "\n",
    "    # Confusion matrix\n",
    "    confusion_matrix = np.zeros((num_classes, num_classes))\n",
    "    for i in range(len(y_pred)):\n",
    "        confusion_matrix[y_true[i], y_pred[i]] += 1\n",
    "\n",
    "    confusion_matrix = confusion_matrix / confusion_matrix.sum(axis=1, keepdims=True) * 100\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(confusion_matrix, annot=True, fmt=\".2f\", cmap=\"viridis\", xticklabels=range(num_classes), yticklabels=range(num_classes))\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.title(\"Confusion Matrix (%)\")\n",
    "    plt.show()\n",
    "\n",
    "    # GradCAM visualization\n",
    "    gradcam_visualize(model, X_test, y_test, num_classes=num_classes, samples=5)\n",
    "\n",
    "# Example Usage\n",
    "# Assume `X_test_processed` and `y_test_processed` are preprocessed test data and labels\n",
    "evaluate_model_with_gradcam(model, X_test_processed, y_test_processed)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
